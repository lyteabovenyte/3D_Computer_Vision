{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425212c1",
   "metadata": {},
   "source": [
    "#### eDiGS Implicit Neural Representation for Unoriented Point Clouds \n",
    "\n",
    "an extended work on [this paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Ben-Shabat_DiGS_Divergence_Guided_Shape_Implicit_Neural_Representation_for_Unoriented_Point_CVPR_2022_paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7471a4",
   "metadata": {},
   "source": [
    "**Surface reconstruction** is the process of converting a sparse 3D point cloud (e.g., obtained from a LiDAR scan or multi-view stereo) into a continuous, watertight 3D surface (typically represented as a mesh or an implicit function like an SDF — signed distance function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a73e28",
   "metadata": {},
   "source": [
    "#### Shape INRs:\n",
    "\n",
    "Shape INRs are INRs trained to represent individual 3D shapes. Specifically, in the context of the eDiGS paper:\n",
    "- A Shape INR is a neural network that represents a specific shape via a latent code or set of parameters.\n",
    "- Each 3D shape (or point cloud) is modeled by its own INR, or by conditioning a shared INR on a latent embedding.\n",
    "\n",
    "These INRs can represent:\n",
    "- The surface of a shape (via level sets of the network),\n",
    "- Occupancy fields (probability a point is inside the shape),\n",
    "- Signed Distance Functions (SDFs).\n",
    "\n",
    "So, in summary:\n",
    "\n",
    "A Shape INR is an instance of an INR that models a single 3D object. It’s a neural function that encodes the geometry of that shape implicitly, usually by taking 3D coordinates and returning occupancy or signed distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5253d",
   "metadata": {},
   "source": [
    "#### Outline of Divergence-Guided Shape INRs:\n",
    "\n",
    "1. **Geometric initialisation**: Initialise to asphere, biasing the function to start with an SDF that is positive away from the object and negative in the centre of the object’s bounding box while keeping\n",
    "the model’s ability to have high frequencies (in a controllable\n",
    "manner).\n",
    "2. **High divergence phase**: Guide the model towards a smooth\n",
    "reconstruction of the coarse shape. Importantly, this prevents the\n",
    "model from prematurely fitting to fine details.\n",
    "3. **Annealing divergence phase**: Slowly allow fine details to\n",
    "emerge while still learning a function that has smoothly changing normals.\n",
    "4. **Low divergence phase**: Allow very fine details such as sharp\n",
    "corners to emerge and for the function to interpolate the original\n",
    "data (point cloud samples) as much as possible (subject to also\n",
    "minimising the eikonal term)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5cd2c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
